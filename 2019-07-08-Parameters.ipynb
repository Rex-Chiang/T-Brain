{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"XIII_5000-s2\"] = features[\"XIII_5000\"] ** 2\n",
    "features[\"XIII_5000-s3\"] = features[\"XIII_5000\"] ** 3\n",
    "features[\"XIII_5000-Sq\"] = np.sqrt(features[\"XIII_5000\"])\n",
    "features[\"jobschool_rate-s2\"] = features[\"jobschool_rate\"] ** 2\n",
    "features[\"jobschool_rate-s3\"] = features[\"jobschool_rate\"] ** 3\n",
    "features[\"jobschool_rate-Sq\"] = np.sqrt(features[\"jobschool_rate\"])\n",
    "features[\"bachelor_rate-s2\"] = features[\"bachelor_rate\"] ** 2\n",
    "features[\"bachelor_rate-s3\"] = features[\"bachelor_rate\"] ** 3\n",
    "features[\"bachelor_rate-Sq\"] = np.sqrt(features[\"bachelor_rate\"])\n",
    "features[\"XIII_10000-s2\"] = features[\"XIII_10000\"] ** 2\n",
    "features[\"XIII_10000-s3\"] = features[\"XIII_10000\"] ** 3\n",
    "features[\"XIII_10000-Sq\"] = np.sqrt(features[\"XIII_10000\"])\n",
    "features[\"VII_10000-s2\"] = features[\"VII_10000\"] ** 2\n",
    "features[\"VII_10000-s3\"] = features[\"VII_10000\"] ** 3\n",
    "features[\"VII_10000-Sq\"] = np.sqrt(features[\"VII_10000\"])\n",
    "features[\"IX_10000-s2\"] = features[\"IX_10000\"] ** 2\n",
    "features[\"IX_10000-s3\"] = features[\"IX_10000\"] ** 3\n",
    "features[\"IX_10000-Sq\"] = np.sqrt(features[\"IX_10000\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the skew of all numerical features\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(10)\n",
    "\n",
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    #all_data[feat] += 1\n",
    "    all_data[feat] = boxcox1p(all_data[feat], lam)\n",
    "    #all_data[skewed_features] = np.log1p(all_data[skewed_features])\n",
    "all_data = pd.get_dummies(all_data)\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "skewness = features_num.apply(lambda x: skew(x))\n",
    "skewness = skewness[abs(skewness) > 1.5]\n",
    "print(str(skewness.shape[0]) + \" skewed numerical features to log transform\")\n",
    "skewed_features = skewness.index\n",
    "features_num[skewed_features] = np.log1p(features_num[skewed_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase or drop features\n",
    "train['building_age'] = train.txn_dt - train.building_complete_dt\n",
    "train.drop(['txn_dt', 'building_complete_dt'], axis=1, inplace=True)\n",
    "# Change the features to categorical\n",
    "train['building_material'] = train['building_material'].astype(str)\n",
    "train['city'] = train['city'].astype(str)\n",
    "train['town'] = train['town'].astype(str)\n",
    "train['village'] = train['village'].astype(str)\n",
    "train['building_type'] = train['building_type'].astype(str)\n",
    "train['building_use'] = train['building_use'].astype(str)\n",
    "train['parking_way'] = train['parking_way'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical variables with target encoding\n",
    "def calc_target_encode(df, by, on, m):\n",
    "    # Compute the global mean\n",
    "    mean = df[on].mean()\n",
    "\n",
    "    # Compute the number of values and the mean of each group\n",
    "    agg = df.groupby(by)[on].agg(['count', 'mean'])\n",
    "    counts = agg['count']\n",
    "    means = agg['mean']\n",
    "\n",
    "    # Compute the \"smoothed\" means\n",
    "    smooth = (counts * means + m * mean) / (counts + m)\n",
    "\n",
    "    # Replace each value by the according smoothed mean\n",
    "    return df[by].map(smooth)\n",
    "\n",
    "for item in items:\n",
    "    train[item] = calc_target_encode(train, by=item, on='total_price', m=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the unmissing part to predict the missing value\n",
    "# from fancyimpute import KNN\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "# X is the complete data matrix\n",
    "# X_incomplete has the same values as X except a subset have been replace with NaN\n",
    "# Use 3 nearest rows which have a feature to fill in each row's missing features\n",
    "train.iloc[:,1:] = IterativeImputer().fit_transform(train.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['txn_floor'] = train['txn_floor'].fillna(round(train.groupby(['building_use','building_type','city'])['txn_floor'].transform('mean')))\n",
    "train['txn_floor'] = train['txn_floor'].fillna(round(train.groupby(['building_type','city'])['txn_floor'].transform('mean')))\n",
    "train['txn_floor'] = train['txn_floor'].fillna(round(train.groupby(['city'])['txn_floor'].transform('mean')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['village_income_median'] = train['village_income_median'].fillna(round(train.groupby(['city','town','village'])['village_income_median'].transform('mean')))\n",
    "train['village_income_median'] = train['village_income_median'].fillna(round(train.groupby(['city','town'])['village_income_median'].transform('mean')))\n",
    "train['village_income_median'] = train['village_income_median'].fillna(round(train.groupby(['city'])['village_income_median'].transform('mean')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
